## Notes on SEO Foundations LinkdIn Leanring Course

### Search Engine Optimisation

- Search engine optimization is the process of making improvements on and off your website in order to gain more exposure in search engine results.
- Search Engine Result Pages (SERPS)

### Foundations

## Chapter 1 - Over view of SEO

### What is search engine optimization?

- Search engine optimization (SEO) aims to improve website visibility in search engine results, attracting more relevant visitors.
- Search engines seek to find and deliver relevant and authoritative content to users.
- Relevance in search results is determined by analyzing web page content, code, and external links.
- Search engines understand semantic and thematic connections between words and concepts, allowing for nuanced search results.
- Authority refers to the trustworthiness of content, evaluated through links, references, and reviews from other websites.
- Links act as votes on the internet, with quality and relevance influencing their value.
- Links from reputable and industry-related sites carry more weight than unrelated or low-quality links.
- SEO success depends on improving both relevance and authority, leading to increased search engine exposure and website visits.

### Reading search engine results

- Search engine results pages (SERPs) typically include paid listings and organic/natural results.
- Paid listings are advertisements placed by advertisers through programs like Google Ads or Microsoft Advertising.
- Organic results are not influenced by advertising and appear below or alongside paid listings.
- SERPs can display various types of content, including videos, images, news, products, maps, and more.
- Search engines use algorithms to determine relevant and appropriate results based on user queries.
- Enhanced results like Google's knowledge graph can provide additional information from various sources like Wikipedia and review sites.
- Understanding how search engines display results helps optimize content for higher visibility and ranking.
- Utilizing structured data can further enhance the chances of content appearing in specific result formats.

## Chapter 2 - Keywords: The foundation of SEO

### Planning and researching your SEO keywords

- Keyword research is crucial for SEO and involves discovering relevant search terms users use to find content.
- Start by brainstorming a list of keywords based on the products, services, and problems your website addresses.
- Consider user intent when selecting keywords; focus on terms that align with what users are looking for.
- Use tools like Google Search Console, Google Trends, AnswerThePublic, and Moz's Keyword Explorer to expand your keyword list.
- Evaluate search volume and competition for each keyword; long tail keywords can be valuable with less competition.
- Long tail keywords may have lower search volume individually but can collectively attract significant traffic.
- Organize keywords into themes or categories for easier management and optimization.
- Keyword research is an ongoing process; continuously revisit and refine your target keyword list based on performance and changes in user behavior.

### Analysing SEO keywords and leveraging keyword attributes

- Keyword research tools are essential for exploring and collecting data on relevant keywords.
- Moz Keyword Explorer is one tool that provides search volume, relevancy scores, and competitive metrics for keyword suggestions.
- Long tail keywords can present opportunities with lower competition and specific user intent.
- Google Trends is another useful tool to understand keyword trends over time, geographic interest, and related keyword ideas.
- Data from keyword research tools can be downloaded and analyzed in spreadsheets for further analysis and keyword selection.
- Keyword research is an ongoing process that informs SEO strategy and helps decide which keywords to prioritize for optimization.


### Mapping SEA keywords and leveraging keyword attributes

- Keyword distribution involves assigning target keywords to specific pages on your website.
- Create a spreadsheet to organize your site's pages, keywords, and key optimization components.
- Populate the spreadsheet with existing content and ensure each page targets a unique and relevant keyword.
- Use the spreadsheet to guide content creation and optimization, including URL, title, meta description, and header.
- Revisit the keyword research and mapping process periodically to stay current with trends and adapt to changing needs.
- Consider paid advertising programs to test the performance of certain keywords before investing in long-term organic SEO strategies.
- Continuously improve your keyword and content strategy over time to achieve better results and drive relevant traffic to your website.


## Chapter 3 - Content Optimization for SEO: How Search Engines and People View Webpages

### Outlining Content Optimization

- Content optimization involves improving the quality and relevance of the content on your website continuously.
- Both people and search engines expect clear and trustworthy content.
- Search engines prioritize content that directly matches users' search queries and provides valuable, relevant information.
- Content optimization involves ensuring that your pages are focused on tight, relevant themes and building trust through high-quality, valuable content.
- Search engines reward websites with higher visibility when users engage with and share their content, signaling trustworthiness and relevance.
- When optimizing content, think about how you, as a human, would assess the content's relevance and usefulness, and aim to provide the same value to search engine users.


### Optimizing site structure

- Developing more content for various keywords requires a well-structured website.
- A meaningful site structure helps search engines understand how your pages relate to one another and enables them to return relevant results to searchers.
- Search engines navigate through websites using internal linking, so having a clean internal linking structure is essential for them to find and understand your content.
- A good site structure is like a well-organized bookstore, with clear categories, subcategories, and links guiding visitors to their desired content efficiently.
- Internal linking and site structure are vital for both search engines and users to find and access your content easily.
- A poorly structured website with broken links and confusing navigation can negatively impact search engine understanding and user experience.
- There is no one-size-fits-all site structure; it should be logical and clear to both you and your visitors.
- Search engines aim to emulate human processes, so a well-designed site structure that is easy for people to navigate will be easily understood by search engines as well.


### Optimising on-page elements

- On-page optimization involves fine-tuning the relevance of a page for a specific keyword or search term.
- The first element to optimize is the URL, which should be concise, descriptive, and contain the target keyword.
- The meta title tag is essential and should be around 65 characters, containing the target keyword and a compelling call to action.
- The meta description tag may not directly impact rankings but can improve click-through rates by providing a compelling description of the page's content.
- The H1 header tag, as the main visible headline, should be concise and descriptive, containing the target keyword.
- Content optimization should focus on delivering value to users while naturally incorporating the target keyword and related terms.
- Images can be optimized by renaming the image files and providing descriptive alt text to help both users and search engines understand the content.
- Surrounding readable text can describe non-text elements like images and videos, helping search engines establish topical correlation.
- Structured data can be used to provide relevant metadata for certain types of content, enhancing search engine understanding and potentially leading to rich results in search listings.
- On-page optimization involves optimizing URLs, titles, meta descriptions, headers, body text, and images, as well as providing structured data for non-text elements.
- Regularly reviewing and optimizing existing pages based on keyword research can yield significant improvements in on-page optimization.

## Chapter 4 - Content Optimization: Technical SEO

### Interpreting the code behind webpages

- Search engines crawl webpages to understand their content, but they can't see the visual elements like humans do.
- Webpages are created with code, scripts, and markup that instruct browsers on how to render the page.
- Clean, efficient, and error-free code helps both human users and search engines have a positive experience.
- Metadata, header tags, and structured data provide additional opportunities for search engines to understand content.
- Dynamic elements like animations may not be as transparent to search engines.
- Optimizing your website's code improves on-page optimization and builds trust with search engines.


### Outlining how search engines index content

- Search engines discover new content through crawling links, sitemaps, and following rules set in the robots.txt file.
- Creating internal links within your website helps search engines find and index new content easily.
- Sitemaps, in XML format, provide an organized list of links to all your site's pages, allowing search engines to understand your site structure.
- You can submit sitemaps directly to search engines to notify them of new or updated content.
- The robots.txt file allows you to set rules for search engine crawlers, controlling how they access and crawl your website.
- Use the noindex meta tag to prevent specific pages from appearing in search engine results entirely.
- Monitor your website's uptime and load times to provide a better user experience for search engine users.
- Switching to HTTPS is best practice as it provides security and may be considered a ranking signal by search engines.
- By following these practices, you can ensure that your pages are indexed properly and quickly by search engines.

### Working with canonicle URLs and redirects: Technical SEO

- Duplicate content can occur when multiple URLs point to the same content on a website, potentially dividing SEO efforts.
- URL parameters can cause duplicate content issues when search engines treat similar URLs as separate pages.
- To address duplicate content caused by URL parameters, you can use the rel canonical meta tag to specify the main URL that should be indexed.
- Another way to handle URL parameters is to inform search engines directly through Google's Search Console and Bing's Webmaster Tools.
- Content moves from one location to another can also lead to duplicate content issues, and implementing redirect rules is crucial in such cases.
- Use a 301 (permanent) redirect for long-term content moves to transfer SEO value from the old URL to the new one.
- Avoid using technologies like JavaScript or Meta Refresh Tags for redirects, as they may cause indexing issues with search engines.
- Having unique and properly handled URLs for each page will improve the chances of proper indexing and higher search engine rankings.

### Leveraging structured data: Technical SEO

- Structured data, often referred to as schema, provides a special syntax to help search engines identify specific types of content on web pages.
- Schema.org is a collection of universal shared vocabulary founded by major search engines to define the structure and attributes of different content elements.
- By using structured data, we can explicitly tell search engines what certain content elements are and provide additional metadata about them.
- For example, structured data can be used to describe elements like product reviews, events, embedded videos, and food recipes, providing attributes such as ratings, dates, authors, and more.
- Leveraging structured data allows search engines to have a deeper semantic understanding of content, leading to more relevant search results for users.
- JSON-LD (JavaScript Object Notation for Linked Data) is the recommended method for implementing structured data.
- There are around 800 types of structured data available on Schema.org, so explore the options and apply relevant data to different types of content on your website.
- Anytime you can specifically identify content using structured data, it's beneficial for both search engines and visitors.

### Using Google Search Console for SEO

- Webmaster tools provided by major search engines (e.g., Google Search Console) offer valuable insights into a website's performance in search results and allow webmasters to provide instructions for crawling and indexing.
- To begin, webmasters need to add their website as a property to the webmaster tool platform and verify ownership through various methods like HTML file upload, meta tag insertion, or DNS record changes.
- The main dashboard in the webmaster tools provides an overview of key reports and messages related to the website.
- The URL inspection feature allows webmasters to see how Google has crawled and indexed specific pages and request reindexing if needed.
- The performance section offers reports on search queries, page performance, impressions, clicks, click-through rate, and average position. These reports can be filtered by various parameters like country, device type, and search appearance.
- The index section includes the coverage report, which identifies issues with content indexing, duplicate content, blocked content, and crawl anomalies.
- The sitemaps feature allows webmasters to submit and monitor the status of XML sitemaps, which help search engines discover and index website content.
- The removal section allows webmasters to temporarily remove specific pages from Google's index.
- The experience section covers mobile usability, page experience, core web vitals, and enhanced features like AMP (Accelerated Mobile Pages) and structured data.
- The security and manual actions reports provide information on potential malware, hacking, or manual actions applied by Google.
- The links section offers insights into external and internal linking, which can aid in off-page and on-page optimization efforts, respectively.
- Webmasters should continually explore and use the various tools, features, and reports offered by webmaster tools to stay informed about their website's performance and address any issues effectively.


### Using the Google Page Experience signal and Core Web Vitals

- Search engines aim to understand your content, business, and site by analyzing how actual human users perceive it. Speed and performance are essential factors in this analysis.
- Google has introduced Core Web Vitals, a collection of metrics to measure and improve overall performance and usability. The three key components are:
  - Largest Contentful Paint (LCP): Measures the time it takes to render the largest content element visible on the screen.
  - First Input Delay (FID): Measures the time from when a user first interacts with the page to when the browser responds.
  - Cumulative Layout Shift (CLS): Measures how much different components in the layout shift around while users interact with the page.
- These metrics can be found in various Google tools, such as PageSpeed Insights and the Core Web Vitals report in Google Search Console.
- PageSpeed Insights provides both field data (real-world user data) and lab data (simulated data) reports. Field data is used for ranking purposes and is crucial to monitor.
- The lab data report in PageSpeed Insights offers detailed diagnostics and improvement opportunities for each metric.
- Core Web Vitals are essential ranking signals, part of the broader set of signals called page experience. Other page experience elements include mobile friendliness, security (HTTPS), and avoiding intrusive interstitials or popups.
- Consistently monitoring Core Web Vitals, fixing issues promptly, and designing for speed, security, and performance will positively impact search visibility and user experience.

### Planning content over the long term   

- Content is crucial for SEO, and a strategy should be built around clear goals and objectives tied to business or organizational objectives.
- Understanding the target audience is essential to create relevant and engaging content that solves their problems and addresses their interests.
- Developing a formal content plan, like a rolling editorial or content calendar, helps organize content creation, keyword targeting, promotion, and accountability.
- Various content types, such as web pages, blog posts, videos, images, infographics, and more, can attract links and shares, boosting search visibility.
- Generating content ideas involves monitoring news, social media, industry groups, and competitors, and leveraging relationships with customers, vendors, and partners.
- Reusing and repurposing existing content can provide additional value and reach different audiences.
- Execution is vital, and content should have impeccable grammar, spelling, and language use to reflect well on the organization.
- Online reputation management is essential to ensure all content aligns with well-crafted and understood policies for writing and publishing.
- Promoting new content through menus, site maps, homepage links, newsletters, and social sharing helps gain visibility and engagement.
- Analyzing content performance using web analytics helps measure its impact on key performance indicators (KPIs) and business objectives.
- Continuous planning, creating, and managing of high-quality content contributes to better search visibility and overall success.

